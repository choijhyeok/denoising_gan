{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StyleBased_Generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0c335d16b485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;31m# Create models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m \u001b[0mgenerator\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[0mStyleBased_Generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_fc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_latent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[0mdiscriminator\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StyleBased_Generator' is not defined"
     ]
    }
   ],
   "source": [
    "# use idel gpu\n",
    "# it's better to use enviroment variable\n",
    "# if you want to use multiple gpus, please\n",
    "# modify hyperparameters at the same time\n",
    "# And Make Sure Your Pytorch Version >= 1.0.1\n",
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3, 2'\n",
    "n_gpu             = 2\n",
    "device            = torch.device('cuda:0')\n",
    "\n",
    "# Original Learning Rate\n",
    "learning_rate   = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "# For anime only\n",
    "# learning_rate     = {512: 0.0015, 1024: 0.002}\n",
    "batch_size_1gpu   = {4: 128, 8: 128, 16: 64, 32: 32, 64: 16, 128: 16}\n",
    "mini_batch_size_1 = 8\n",
    "batch_size        = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
    "mini_batch_size   = 8\n",
    "batch_size_4gpus  = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
    "mini_batch_size_4 = 16\n",
    "batch_size_8gpus  = {4: 512, 8: 256, 16: 128, 32: 64}\n",
    "mini_batch_size_8 = 32\n",
    "# Commen line below if you don't meet the problem of 'shared memory conflict'\n",
    "num_workers       = {128: 8, 256: 4, 512: 2}\n",
    "max_workers       = 16\n",
    "n_fc              = 8\n",
    "dim_latent        = 512\n",
    "dim_input         = 4\n",
    "# number of samples to show before dowbling resolution\n",
    "n_sample          = 600_000\n",
    "# number of samples train model in total\n",
    "n_sample_total    = 10_000_000\n",
    "DGR               = 1\n",
    "n_show_loss       = 360\n",
    "step              = 1 # Train from (8 * 8)\n",
    "max_step          = 7\n",
    "style_mixing      = [] # Waiting to implement\n",
    "image_folder_path = './dataset/'\n",
    "save_folder_path  = './results/'\n",
    "\n",
    "low_steps         = [0, 1, 2]\n",
    "# style_mixing    += low_steps\n",
    "mid_steps         = [3, 4, 5]\n",
    "# style_mixing    += mid_steps\n",
    "hig_steps         = [6, 7, 8]\n",
    "# style_mixing    += hig_steps\n",
    "\n",
    "# Used to continue training from last checkpoint\n",
    "iteration         = 0\n",
    "startpoint        = 0\n",
    "used_sample       = 0\n",
    "alpha             = 0\n",
    "\n",
    "# How to start training?\n",
    "# True for start from saved model\n",
    "# False for retrain from the very beginning\n",
    "is_continue       = True\n",
    "d_losses          = [float('inf')]\n",
    "g_losses          = [float('inf')]\n",
    "\n",
    "def set_grad_flag(module, flag):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "def reset_LR(optimizer, lr):\n",
    "    for pam_group in optimizer.param_groups:\n",
    "        mul = pam_group.get('mul', 1)\n",
    "        pam_group['lr'] = lr * mul\n",
    "        \n",
    "# Gain sample\n",
    "def gain_sample(dataset, batch_size, image_size=4):\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(image_size),          # Resize to the same size\n",
    "            transforms.CenterCrop(image_size),      # Crop to get square area\n",
    "            transforms.RandomHorizontalFlip(),      # Increase number of samples\n",
    "            transforms.ToTensor(),            \n",
    "            transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                 (0.5, 0.5, 0.5))])\n",
    "\n",
    "    dataset.transform = transform\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers.get(image_size, max_workers))\n",
    "\n",
    "    return loader\n",
    "\n",
    "def imsave(tensor, i):\n",
    "    grid = tensor[0]\n",
    "    grid.clamp_(-1, 1).add_(1).div_(2)\n",
    "    # Add 0.5 after normalizing to [0, 255] to round to nearest integer\n",
    "    ndarr = grid.mul_(255).add_(0.5).clamp_(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "    img = Image.fromarray(ndarr)\n",
    "    img.save(f'{save_folder_path}sample-iter{i}.png')\n",
    "    \n",
    "# Train function\n",
    "def train(generator, discriminator, g_optim, d_optim, dataset, step, iteration=0, startpoint=0, used_sample=0,\n",
    "         d_losses = [], g_losses = [], alpha=0):\n",
    "    \n",
    "    resolution  = 4 * 2 ** step\n",
    "    \n",
    "    origin_loader = gain_sample(dataset, batch_size.get(resolution, mini_batch_size), resolution)\n",
    "    data_loader = iter(origin_loader)\n",
    "    \n",
    "    reset_LR(g_optim, learning_rate.get(resolution, 0.001))\n",
    "    reset_LR(d_optim, learning_rate.get(resolution, 0.001))\n",
    "    progress_bar = tqdm(total=n_sample_total, initial=used_sample)\n",
    "    # Train\n",
    "    while used_sample < n_sample_total:\n",
    "        iteration += 1\n",
    "        alpha = min(1, alpha + batch_size.get(resolution, mini_batch_size) / (n_sample))\n",
    "        \n",
    "        if (used_sample - startpoint) > n_sample and step < max_step: \n",
    "            step += 1\n",
    "            alpha = 0\n",
    "            startpoint = used_sample\n",
    "            \n",
    "            resolution = 4 * 2 ** step\n",
    "            \n",
    "            # Avoid possible memory leak\n",
    "            del origin_loader\n",
    "            del data_loader\n",
    "            \n",
    "            # Change batch size\n",
    "            origin_loader = gain_sample(dataset, batch_size.get(resolution, mini_batch_size), resolution)\n",
    "            data_loader = iter(origin_loader)\n",
    "            \n",
    "            reset_LR(g_optim, learning_rate.get(resolution, 0.001))\n",
    "            reset_LR(d_optim, learning_rate.get(resolution, 0.001))\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            # Try to read next image\n",
    "            real_image, label = next(data_loader)\n",
    "\n",
    "        except (OSError, StopIteration):\n",
    "            # Dataset exhausted, train from the first image\n",
    "            data_loader = iter(origin_loader)\n",
    "            real_image, label = next(data_loader)\n",
    "        \n",
    "        # Count used sample\n",
    "        used_sample += real_image.shape[0]\n",
    "        progress_bar.update(real_image.shape[0])\n",
    "        \n",
    "        # Send image to GPU\n",
    "        real_image = real_image.to(device)\n",
    "        \n",
    "        # D Module ---\n",
    "        # Train discriminator first\n",
    "        discriminator.zero_grad()\n",
    "        set_grad_flag(discriminator, True)\n",
    "        set_grad_flag(generator, False)\n",
    "        \n",
    "        # Real image predict & backward\n",
    "        # We only implement non-saturating loss with R1 regularization loss\n",
    "        real_image.requires_grad = True\n",
    "        if n_gpu > 1:\n",
    "            real_predict = nn.parallel.data_parallel(discriminator, (real_image, step, alpha), range(n_gpu))\n",
    "        else:\n",
    "            real_predict = discriminator(real_image, step, alpha)\n",
    "        real_predict = nn.functional.softplus(-real_predict).mean()\n",
    "        real_predict.backward(retain_graph=True)\n",
    "\n",
    "        grad_real = torch.autograd.grad(outputs=real_predict.sum(), inputs=real_image, create_graph=True)[0]\n",
    "        grad_penalty_real = (grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2).mean()\n",
    "        grad_penalty_real = 10 / 2 * grad_penalty_real\n",
    "        grad_penalty_real.backward()\n",
    "        \n",
    "        # Generate latent code\n",
    "        latent_w1 = [torch.randn((batch_size.get(resolution, mini_batch_size), dim_latent), device=device)]\n",
    "        latent_w2 = [torch.randn((batch_size.get(resolution, mini_batch_size), dim_latent), device=device)]\n",
    "\n",
    "        noise_1 = []\n",
    "        noise_2 = []\n",
    "        for m in range(step + 1):\n",
    "            size = 4 * 2 ** m # Due to the upsampling, size of noise will grow\n",
    "            noise_1.append(torch.randn((batch_size.get(resolution, mini_batch_size), 1, size, size), device=device))\n",
    "            noise_2.append(torch.randn((batch_size.get(resolution, mini_batch_size), 1, size, size), device=device))\n",
    "        \n",
    "        # Generate fake image & backward\n",
    "        if n_gpu > 1:\n",
    "            fake_image = nn.parallel.data_parallel(generator, (latent_w1, step, alpha, noise_1), range(n_gpu))\n",
    "            fake_predict = nn.parallel.data_parallel(discriminator, (fake_image, step, alpha), range(n_gpu))\n",
    "        else:\n",
    "            fake_image = generator(latent_w1, step, alpha, noise_1)\n",
    "            fake_predict = discriminator(fake_image, step, alpha)\n",
    "\n",
    "        fake_predict = nn.functional.softplus(fake_predict).mean()\n",
    "        fake_predict.backward()\n",
    "        \n",
    "        if iteration % n_show_loss == 0:\n",
    "            d_losses.append((real_predict + fake_predict).item())\n",
    "        \n",
    "        # D optimizer step\n",
    "        d_optim.step()\n",
    "        \n",
    "        # Avoid possible memory leak\n",
    "        del grad_penalty_real, grad_real, fake_predict, real_predict, fake_image, real_image, latent_w1\n",
    "                   \n",
    "        # G module ---\n",
    "        if iteration % DGR != 0: continue\n",
    "        # Due to DGR, train generator\n",
    "        generator.zero_grad()\n",
    "        set_grad_flag(discriminator, False)\n",
    "        set_grad_flag(generator, True)\n",
    "        \n",
    "        if n_gpu > 1:\n",
    "            fake_image = nn.parallel.data_parallel(generator, (latent_w2, step, alpha, noise_2), range(n_gpu))\n",
    "            fake_predict = nn.parallel.data_parallel(discriminator, (fake_image, step, alpha), range(n_gpu))\n",
    "        else: \n",
    "            fake_image = generator(latent_w2, step, alpha, noise_2)\n",
    "            fake_predict = discriminator(fake_image, step, alpha)\n",
    "        fake_predict = nn.functional.softplus(-fake_predict).mean()\n",
    "        fake_predict.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        if iteration % n_show_loss == 0:\n",
    "            g_losses.append(fake_predict.item())\n",
    "            imsave(fake_image.data.cpu(), iteration)\n",
    "            \n",
    "        # Avoid possible memory leak\n",
    "        del fake_predict, fake_image, latent_w2\n",
    "        \n",
    "        if iteration % 1000 == 0:\n",
    "            # Save the model every 1000 iterations\n",
    "            torch.save({\n",
    "                'generator'    : generator.state_dict(),\n",
    "                'discriminator': discriminator.state_dict(),\n",
    "                'g_optim'      : g_optim.state_dict(),\n",
    "                'd_optim'      : d_optim.state_dict(),\n",
    "                'parameters'   : (step, iteration, startpoint, used_sample, alpha),\n",
    "                'd_losses'     : d_losses,\n",
    "                'g_losses'     : g_losses\n",
    "            }, 'checkpoint/trained.pth')\n",
    "            print(f'Model successfully saved.')\n",
    "        \n",
    "        progress_bar.set_description((f'Resolution: {resolution}*{resolution}  D_Loss: {d_losses[-1]:.4f}  G_Loss: {g_losses[-1]:.4f}  Alpha: {alpha:.4f}'))\n",
    "    torch.save({\n",
    "        'generator'    : generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'g_optim'      : g_optim.state_dict(),\n",
    "        'd_optim'      : d_optim.state_dict(),\n",
    "        'parameters'   : (step, iteration, startpoint, used_sample, alpha),\n",
    "        'd_losses'     : d_losses,\n",
    "        'g_losses'     : g_losses\n",
    "    }, 'checkpoint/trained.pth')\n",
    "    print(f'Final model successfully saved.')    \n",
    "    return d_losses, g_losses\n",
    "\n",
    "\n",
    "# generator      = nn.DataParallel(StyleBased_Generator(n_fc, dim_latent, dim_input)).cuda()\n",
    "# discriminator  = nn.DataParallel(Discriminator()).cuda()  \n",
    "# g_optim        = optim.Adam([{\n",
    "#     'params': generator.module.convs.parameters(),\n",
    "#     'lr'    : 0.001\n",
    "# }, {\n",
    "#     'params': generator.module.to_rgbs.parameters(),\n",
    "#     'lr'    : 0.001\n",
    "# }], lr=0.001, betas=(0.0, 0.99))\n",
    "# g_optim.add_param_group({\n",
    "#     'params': generator.module.fcs.parameters(),\n",
    "#     'lr'    : 0.001 * 0.01,\n",
    "#     'mul'   : 0.01\n",
    "# })\n",
    "\n",
    "# Create models\n",
    "generator      = StyleBased_Generator(n_fc, dim_latent, dim_input).to(device)\n",
    "discriminator  = Discriminator().to(device)\n",
    "\n",
    "# Optimizers\n",
    "g_optim        = optim.Adam([{\n",
    "    'params': generator.convs.parameters(),\n",
    "    'lr'    : 0.001\n",
    "}, {\n",
    "    'params': generator.to_rgbs.parameters(),\n",
    "    'lr'    : 0.001\n",
    "}], lr=0.001, betas=(0.0, 0.99))\n",
    "g_optim.add_param_group({\n",
    "    'params': generator.fcs.parameters(),\n",
    "    'lr'    : 0.001 * 0.01,\n",
    "    'mul'   : 0.01\n",
    "})\n",
    "d_optim        = optim.Adam(discriminator.parameters(), lr=0.001, betas=(0.0, 0.99))\n",
    "dataset        = datasets.ImageFolder(image_folder_path)\n",
    "\n",
    "if is_continue:\n",
    "    if os.path.exists('checkpoint/trained.pth'):\n",
    "        # Load data from last checkpoint\n",
    "        print('Loading pre-trained model...')\n",
    "        checkpoint = torch.load('checkpoint/trained.pth')\n",
    "        generator.load_state_dict(checkpoint['generator'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        g_optim.load_state_dict(checkpoint['g_optim'])\n",
    "        d_optim.load_state_dict(checkpoint['d_optim'])\n",
    "        step, iteration, startpoint, used_sample, alpha = checkpoint['parameters']\n",
    "        d_losses = checkpoint.get('d_losses', [float('inf')])\n",
    "        g_losses = checkpoint.get('g_losses', [float('inf')])\n",
    "        print('Start training from loaded model...')\n",
    "    else:\n",
    "        print('No pre-trained model detected, restart training...')\n",
    "        \n",
    "generator.train()\n",
    "discriminator.train()    \n",
    "d_losses, g_losses = train(generator, discriminator, g_optim, d_optim, dataset, step, iteration, startpoint, used_sample, d_losses, g_losses, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
